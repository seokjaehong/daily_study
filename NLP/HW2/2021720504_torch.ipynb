{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021720504_torch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Zz8Q3e9iQroL",
        "ofHYy5NsCpwY",
        "Ighl1h68UDCB",
        "ra8NgFTOCy-p"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w8ew706HC5C"
      },
      "source": [
        "# 트위터 감정 분석\n",
        "\n",
        "이번 실습에서는 트위터 메시지(트윗)의 감정을 분석하는 RNN Classifier를 만들겠습니다.\n",
        "\n",
        "감정에는 긍정, 부정, 중립의 세 가지 레이블이 있습니다.\n",
        "\n",
        "이 정의에 따라 트윗에 담긴 감정을 태깅하였고 이 데이터를 통해 주어진 트윗에 감정을 분석하는 classifier를 만드는 것이 이번 실습에서의 목표입니다.\n",
        "\n",
        "이전 실습에서는 tensorflow로 작성하였다면 이번에는 또 다른 딥러닝 라이브러리인 [pytorch](https://pytorch.org/)로 작성하겠습니다.\n",
        "\n",
        "이후 딥러닝 관련 실습에서는 pytorch로 진행하겠습니다.\n",
        "\n",
        "pytorch와 tensorflow는 대동소이하여 예제로써 둘의 차이를 파악하시면 큰 어려움 없이 transfer learning을 하실 수 있으실 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjj7XEd3BuDy"
      },
      "source": [
        "## 데이터 파일 다운로드\n",
        "\n",
        "데이터 파일을 다운로드 하기 위해 특수 명령어인 gdown을 사용하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3hwEF6GAiEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aecd2201-11d1-4049-cf82-74c2668a54d7"
      },
      "source": [
        "!gdown --id 1CElFsrPshUPyLIDk0MpkJR01cIcqNdra\n",
        "\n",
        "!gdown --id 1tll145FRmWH8pfnlOCV_mYb3MTLvxf4K\n",
        "\n",
        "!gdown --id 1WJOfcaaW_5nc0Dr573FhX5zFyC5NCp9Z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CElFsrPshUPyLIDk0MpkJR01cIcqNdra\n",
            "To: /content/vocab.csv\n",
            "100% 32.3k/32.3k [00:00<00:00, 21.3MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tll145FRmWH8pfnlOCV_mYb3MTLvxf4K\n",
            "To: /content/valid.csv\n",
            "100% 31.5k/31.5k [00:00<00:00, 23.1MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WJOfcaaW_5nc0Dr573FhX5zFyC5NCp9Z\n",
            "To: /content/train.csv\n",
            "100% 124k/124k [00:00<00:00, 39.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S03tCoPkG6vr"
      },
      "source": [
        "`train.csv` 파일을 열어보면 한 라인에 두 개의 열이 있습니다. \n",
        "\n",
        "첫 번째 열에는 트위터 메시지인 트윗이 있고 오른쪽에는 태깅된 감정이 있습니다.\n",
        "\n",
        "- 0: 부정\n",
        "- 1: 중립\n",
        "- 2: 긍정\n",
        "\n",
        "이렇게 세 가지의 감정이 태깅된 것을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xumuS251GFJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284cc7be-0050-491d-ce5e-a692c65256ff"
      },
      "source": [
        "with open(\"train.csv\") as csv_f:\n",
        "    head = \"\\n\".join([next(csv_f) for x in range(5)])\n",
        "print(head)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "critic survey ashford hospit prime ahp amp kimco realti kim,0\n",
            "\n",
            "analyst adopt bullish outlook robert half intern inc rhi,1\n",
            "\n",
            "zack rank strong buy semiconductor stock mlnx intc mchp,2\n",
            "\n",
            "setup like watch wed roku iq sfix shop spot ual goo twlo nflx xrt tsla sq bidu pypl labu biib kss kre,2\n",
            "\n",
            "invesco ivz price target lower credit suiss group,1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvdTJtt1CcRU"
      },
      "source": [
        "## 라이브러리 로드\n",
        "\n",
        "코드 실행에 필요한 라이브러리를 설치하고 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp7lkHPDvLVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafdc7bd-f334-4e76-bb51-41ba08641905"
      },
      "source": [
        "!pip install -U torchtext==0.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.8.0\n",
            "  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.21.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (4.1.1)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "Successfully installed torchtext-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgnaF87tCfhj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.optim\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.tokenize import word_tokenize\n",
        "import os\n",
        "import nltk\n",
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlUeGHEJPZeV"
      },
      "source": [
        "## 모델 클래스 정의\n",
        "\n",
        "pytorch는 딥러닝 모델의 forward path를 정의할 때는 반드시 `nn.Module` 클래스로부터 상속을 받아 새로운 클래스로 만들어야 합니다.\n",
        "\n",
        "그리고 그 forward path를 정의하기 위해 반드시 `forward` 함수를 정의하여야 합니다.\n",
        "\n",
        "이번 실습에서는 RNN을 이용한 classifier이기에 그에 적합한 클래스를 작성하였습니다.\n",
        "\n",
        "- 문제 1. `LSTMClassifier` 클래스 내 model 구성에 있어 마지막에 classification을 위해 dense layer를 추가해주세요. \n",
        "  - 힌트 1) class의 개수는 3개입니다. \n",
        "  - 힌트 2) dense layer는 `nn.Linear`([매뉴얼 문서](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html))로 만들 수 있습니다.\n",
        "  - 힌트 3) LSTM은 bidirection 즉, 양방향입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pia7XebEPbS1"
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    # LSTM Classifier 클래스를 정의합니다. Pytorch는 모델을 구성할 때 반드시 nn.Module 클래스를 상속받은 후 이를 토대로 만듭니다.\n",
        "    def __init__(self, vocab_size, dimension=128):\n",
        "        # 클래스의 첫 시작인 함수입니다. 여기서 모델에 필요한 여러 변수들을 정의합니다.\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "\n",
        "        # LSTM Classifier에 필요한 변수들을 각각 정의합니다.\n",
        "        self.embedding = nn.Embedding(vocab_size, 300)\n",
        "        self.dimension = dimension\n",
        "        self.lstm = nn.LSTM(input_size=300, hidden_size=dimension, num_layers=1, batch_first=True, bidirectional=True) ## LSTM 모델 생성\n",
        "        self.drop = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.fc = nn.Linear(2*dimension, 3)\n",
        "\n",
        "    def forward(self, text, text_len):\n",
        "        # 모델의 forward feed를 수행하는 함수입니다.\n",
        "        # text와 text_len 변수를 입력으로 받아 신경망 모델을 forward 방향으로 탈 때 그 출력을 반환합니다.\n",
        "        # 단어 => encoder => Embedding => 양방향 RNN => Dense => Dense의 구조입니다.\n",
        "        text_emb = self.embedding(text)\n",
        "\n",
        "        # 글마다 길이가 다르기에 이를 하나의 batch에서 사용하고자 pack_padded_sequence 함수를 통해 padding을 수행합니다.\n",
        "        packed_input = pack_padded_sequence(text_emb, text_len.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        packed_output, _ = self.lstm(packed_input)\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "        out_forward = output[range(len(output)), text_len - 1, :self.dimension]\n",
        "        out_reverse = output[:, 0, self.dimension:]\n",
        "        out_reduced = torch.cat((out_forward, out_reverse), 1)\n",
        "        text_fea = self.drop(out_reduced)\n",
        "\n",
        "        # <ToDo>: model의 마지막에 classification을 위해 dense layer를 추가해주세요.\n",
        "        text_out = self.fc(text_fea)\n",
        "\n",
        "        return text_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZhhZRkJChKT"
      },
      "source": [
        "## train 함수\n",
        "\n",
        "해당 함수에서는 정의된 `model` 클래스의 인스턴스를 가져와서 이를 train data로 학습시킵니다. 그리고 validation data로 학습 중간에 성능을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYucrg5wCjyA"
      },
      "source": [
        "#from tensorflow.keras.callbacks import EarlyStopping\n",
        "#early_stopping = EarlyStopping()\n",
        "\n",
        "def train(model, device, optimizer, train_loader, valid_loader, output_file_path, num_epochs):\n",
        "    # 학습에 필요한 변수들을 기본적으로 정의합니다.\n",
        "    running_loss = 0.0\n",
        "    global_step = 0\n",
        "    train_loss_list = list()\n",
        "    valid_loss_list = list()\n",
        "    global_steps_list = list()\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    best_valid_loss = float(\"Inf\")\n",
        "    eval_every = 10\n",
        "\n",
        "    # model에게 학습이 진행됨을 알려줍니다.\n",
        "    model.train()\n",
        "    # num_epochs만큼 epoch을 반복합니다.\n",
        "    for epoch in range(num_epochs):\n",
        "        # train_loader를 읽으면 정해진 데이터를 읽어옵니다.\n",
        "        for ((text, text_len), labels), _ in train_loader:\n",
        "            # 데이터를 GPU로 옮깁니다.\n",
        "            text = text.to(device)\n",
        "            text_len = text_len.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # model을 함수처럼 호출하면 model에서 정의한 forward 함수가 실행됩니다.\n",
        "            # 즉, 데이터를 모델에 집어넣어 forward방향으로 흐른 후 그 결과를 받습니다.\n",
        "            output = model(text, text_len)\n",
        "\n",
        "            # forward 결과와 실제 데이터 결과의 차이를 정의한 loss 함수로 구합니다.\n",
        "            loss = loss_fn(output, labels)\n",
        "\n",
        "            # 최적화 수행\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_every == 0:\n",
        "                # 100번에 한 번으로 validation 데이터를 이용하여 성능을 검증합니다.\n",
        "                average_train_loss, average_valid_loss = evaluate(model, device, valid_loader, loss_fn,\n",
        "                                                                  running_loss, eval_every)\n",
        "                \n",
        "                # 검증이 끝난 후 다시 모델에게 학습을 준비시킵니다.\n",
        "                running_loss = 0.0\n",
        "                model.train()\n",
        "\n",
        "                # 결과 출력\n",
        "                print('Epoch {}, Step {}, Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
        "                      .format(epoch + 1, global_step, average_train_loss, average_valid_loss))\n",
        "\n",
        "                # 결과 저장\n",
        "                train_loss_list.append(average_train_loss)\n",
        "                valid_loss_list.append(average_valid_loss)\n",
        "                global_steps_list.append(global_step)\n",
        "\n",
        "                # 만약 기존 것보다 성능이 높게 나왔다면 현재 모델 상태를 저장합니다.\n",
        "                if best_valid_loss > average_valid_loss:\n",
        "                    best_valid_loss = average_valid_loss\n",
        "                    save_checkpoint(output_file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
        "                    save_metrics(output_file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "\n",
        "    # 결과를 저장합니다.\n",
        "    save_metrics(output_file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz8Q3e9iQroL"
      },
      "source": [
        "## evaluate 함수\n",
        "\n",
        "해당 함수에서는 validation data를 이용하여 학습된 `model`을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PcidZwmQuFu"
      },
      "source": [
        "def evaluate(model, device, valid_loader, loss_fn, running_loss, eval_every):\n",
        "    # 학습 중 모델을 평가합니다.\n",
        "    # 모델에게 학습이 아닌 평가를 할 것이라고 알립니다.\n",
        "    model.eval()\n",
        "    valid_running_loss = 0.\n",
        "\n",
        "    # 학습이 아니기에 최적화를 하지 않는다는 환경을 설정합니다.\n",
        "    with torch.no_grad():\n",
        "        # validation 데이터를 읽습니다.\n",
        "        for ((text, text_len), labels), _ in valid_loader:\n",
        "            labels = labels.to(device)\n",
        "            text = text.to(device)\n",
        "            text_len = text_len.to(device)\n",
        "            \n",
        "            # model을 함수처럼 호출하면 model에서 정의한 forward 함수가 실행됩니다.\n",
        "            # 즉, 데이터를 모델에 집어넣어 forward방향으로 흐른 후 그 결과를 받습니다.\n",
        "            output = model(text, text_len)\n",
        "\n",
        "            # validation 데이터의 loss, 즉 모델의 출력과 실제 데이터의 차이를 구합니다.\n",
        "            loss = loss_fn(output, labels)\n",
        "            valid_running_loss += loss.item()\n",
        "\n",
        "    # 평균 loss를 계산합니다.\n",
        "    average_train_loss = running_loss / eval_every\n",
        "    average_valid_loss = valid_running_loss / len(valid_loader)\n",
        "\n",
        "    return average_train_loss, average_valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofHYy5NsCpwY"
      },
      "source": [
        "## 그래프 그리는 함수\n",
        "\n",
        "epoch에 따른 train loss와 validation loss 그래프를 그립니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTXXPgoLCpiC"
      },
      "source": [
        "def draw_graph(output_file_path, device):\n",
        "    train_loss_list, valid_loss_list, global_steps_list = load_metrics(output_file_path + '/metrics.pt', device)\n",
        "    plt.plot(global_steps_list, train_loss_list, label='Train')\n",
        "    plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
        "    plt.xlabel('Global Steps')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(\"train_valid_loss.png\", bbox_inches='tight')\n",
        "\n",
        "    Image('train_valid_loss.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ighl1h68UDCB"
      },
      "source": [
        "## 모델 및 기록 저장 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcpFZHyVUFr8"
      },
      "source": [
        "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "\n",
        "\n",
        "def load_checkpoint(load_path, model, optimizer, device):\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
        "\n",
        "    return state_dict['valid_loss']\n",
        "\n",
        "\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "\n",
        "\n",
        "def load_metrics(load_path, device):\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "\n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra8NgFTOCy-p"
      },
      "source": [
        "## 데이터 불러오기\n",
        "\n",
        "- 문제 2. `valid_loader`를 불러오세요. 힌트) `train_loader`을 참고하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jy8JWuPCyvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c222af4e-9289-4b79-fd49-2ee9b2fca7b9"
      },
      "source": [
        "# nltk의 토크나이저를 사용하기에 이를 다운로드 받습니다.\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 데이터의 기본 형태에 대한 정보입니다.\n",
        "output_file_path=\"./model/\"\n",
        "os.makedirs(output_file_path, exist_ok=True)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.long)\n",
        "text_field = Field(tokenize=word_tokenize, lower=True, include_lengths=True, batch_first=True)\n",
        "fields = [('text', text_field), ('labels', label_field)]\n",
        "\n",
        "# train, validation 데이터 csv 파일을 읽어옵니다.\n",
        "train_data, valid_data = TabularDataset.splits(path=\"./\", train='train.csv', validation='valid.csv',\n",
        "                                               format='CSV', fields=fields, skip_header=True)\n",
        "train_loader = BucketIterator(train_data, batch_size=32, sort_key=lambda x: len(x.text),\n",
        "                              device=device, sort=True, sort_within_batch=True)\n",
        "\n",
        "# <ToDo>: valid_dataset을 불러오세요.\n",
        "# valid_loader = None # Problem 2\n",
        "valid_loader = BucketIterator(valid_data, batch_size=32, sort_key=lambda x: len(x.text),\n",
        "                              device=device, sort=True, sort_within_batch=True)\n",
        "\n",
        "text_field.build_vocab(train_data, min_freq=3)\n",
        "vocab_size = len(text_field.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhYDMPM7A4iy",
        "outputId": "76f9bc83-f64d-45d8-ef26-b743d3e88b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1658"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNlcKZKoDDEq"
      },
      "source": [
        "## 모델 학습\n",
        "\n",
        "- 문제 3. `train` 함수를 이용하여 train data를 통해 모델 학습을 진행하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpjT1fyTDF15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab4e3025-444d-449a-e5d0-e68308387dfd"
      },
      "source": [
        "# 앞서 정의한 LSTMClassifier 클래스의 인스턴스를 만듭니다.\n",
        "model = LSTMClassifier(vocab_size).to(device)\n",
        "# Adam optimizier를 사용합니다.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# <ToDo>: 학습을 위해 train 함수의 적절한 parameter를 전달해주세요.\n",
        "# train(None)  # Problem 3\n",
        "# (model, device, optimizer, train_loader, valid_loader, output_file_path, num_epochs):\n",
        "train(model, device,optimizer,train_loader,valid_loader,output_file_path,30)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Step 10, Train Loss: 0.9508, Valid Loss: 0.9524\n",
            "Epoch 1, Step 20, Train Loss: 0.8410, Valid Loss: 0.9666\n",
            "Epoch 1, Step 30, Train Loss: 0.9671, Valid Loss: 0.8375\n",
            "Epoch 1, Step 40, Train Loss: 0.9428, Valid Loss: 0.7998\n",
            "Epoch 1, Step 50, Train Loss: 0.8815, Valid Loss: 0.8243\n",
            "Epoch 1, Step 60, Train Loss: 0.9545, Valid Loss: 0.7702\n",
            "Epoch 2, Step 70, Train Loss: 0.6226, Valid Loss: 0.7241\n",
            "Epoch 2, Step 80, Train Loss: 0.5151, Valid Loss: 0.7603\n",
            "Epoch 2, Step 90, Train Loss: 0.6687, Valid Loss: 0.7292\n",
            "Epoch 2, Step 100, Train Loss: 0.6268, Valid Loss: 0.6530\n",
            "Epoch 2, Step 110, Train Loss: 0.6398, Valid Loss: 0.6760\n",
            "Epoch 2, Step 120, Train Loss: 0.7527, Valid Loss: 0.6669\n",
            "Epoch 3, Step 130, Train Loss: 0.4977, Valid Loss: 0.5718\n",
            "Epoch 3, Step 140, Train Loss: 0.3056, Valid Loss: 0.6049\n",
            "Epoch 3, Step 150, Train Loss: 0.3532, Valid Loss: 0.6110\n",
            "Epoch 3, Step 160, Train Loss: 0.3176, Valid Loss: 0.5334\n",
            "Epoch 3, Step 170, Train Loss: 0.3656, Valid Loss: 0.5466\n",
            "Epoch 3, Step 180, Train Loss: 0.4230, Valid Loss: 0.5365\n",
            "Epoch 4, Step 190, Train Loss: 0.4070, Valid Loss: 0.5421\n",
            "Epoch 4, Step 200, Train Loss: 0.1906, Valid Loss: 0.5046\n",
            "Epoch 4, Step 210, Train Loss: 0.1819, Valid Loss: 0.6716\n",
            "Epoch 4, Step 220, Train Loss: 0.1426, Valid Loss: 0.5366\n",
            "Epoch 4, Step 230, Train Loss: 0.1710, Valid Loss: 0.4881\n",
            "Epoch 4, Step 240, Train Loss: 0.1706, Valid Loss: 0.5521\n",
            "Epoch 4, Step 250, Train Loss: 0.2215, Valid Loss: 0.4918\n",
            "Epoch 5, Step 260, Train Loss: 0.1011, Valid Loss: 0.5288\n",
            "Epoch 5, Step 270, Train Loss: 0.1039, Valid Loss: 0.5245\n",
            "Epoch 5, Step 280, Train Loss: 0.0699, Valid Loss: 0.7101\n",
            "Epoch 5, Step 290, Train Loss: 0.0984, Valid Loss: 0.5448\n",
            "Epoch 5, Step 300, Train Loss: 0.0699, Valid Loss: 0.5600\n",
            "Epoch 5, Step 310, Train Loss: 0.0927, Valid Loss: 0.5309\n",
            "Epoch 6, Step 320, Train Loss: 0.0816, Valid Loss: 0.5147\n",
            "Epoch 6, Step 330, Train Loss: 0.0710, Valid Loss: 0.5089\n",
            "Epoch 6, Step 340, Train Loss: 0.0411, Valid Loss: 0.5230\n",
            "Epoch 6, Step 350, Train Loss: 0.0499, Valid Loss: 0.6203\n",
            "Epoch 6, Step 360, Train Loss: 0.0650, Valid Loss: 0.5102\n",
            "Epoch 6, Step 370, Train Loss: 0.0695, Valid Loss: 0.5941\n",
            "Epoch 7, Step 380, Train Loss: 0.0652, Valid Loss: 0.6152\n",
            "Epoch 7, Step 390, Train Loss: 0.0334, Valid Loss: 0.8098\n",
            "Epoch 7, Step 400, Train Loss: 0.0330, Valid Loss: 0.7518\n",
            "Epoch 7, Step 410, Train Loss: 0.0326, Valid Loss: 0.7433\n",
            "Epoch 7, Step 420, Train Loss: 0.0294, Valid Loss: 0.6637\n",
            "Epoch 7, Step 430, Train Loss: 0.0563, Valid Loss: 0.5808\n",
            "Epoch 7, Step 440, Train Loss: 0.0773, Valid Loss: 0.6860\n",
            "Epoch 8, Step 450, Train Loss: 0.0391, Valid Loss: 0.5894\n",
            "Epoch 8, Step 460, Train Loss: 0.0406, Valid Loss: 0.5592\n",
            "Epoch 8, Step 470, Train Loss: 0.0163, Valid Loss: 0.6281\n",
            "Epoch 8, Step 480, Train Loss: 0.0171, Valid Loss: 0.6839\n",
            "Epoch 8, Step 490, Train Loss: 0.0239, Valid Loss: 0.6089\n",
            "Epoch 8, Step 500, Train Loss: 0.0359, Valid Loss: 0.6053\n",
            "Epoch 9, Step 510, Train Loss: 0.0269, Valid Loss: 0.7444\n",
            "Epoch 9, Step 520, Train Loss: 0.0271, Valid Loss: 0.7257\n",
            "Epoch 9, Step 530, Train Loss: 0.0175, Valid Loss: 0.6397\n",
            "Epoch 9, Step 540, Train Loss: 0.0262, Valid Loss: 0.6514\n",
            "Epoch 9, Step 550, Train Loss: 0.0069, Valid Loss: 0.6958\n",
            "Epoch 9, Step 560, Train Loss: 0.0206, Valid Loss: 0.6461\n",
            "Epoch 10, Step 570, Train Loss: 0.0123, Valid Loss: 0.6558\n",
            "Epoch 10, Step 580, Train Loss: 0.0061, Valid Loss: 0.7018\n",
            "Epoch 10, Step 590, Train Loss: 0.0065, Valid Loss: 0.7298\n",
            "Epoch 10, Step 600, Train Loss: 0.0091, Valid Loss: 0.7086\n",
            "Epoch 10, Step 610, Train Loss: 0.0106, Valid Loss: 0.6926\n",
            "Epoch 10, Step 620, Train Loss: 0.0026, Valid Loss: 0.7144\n",
            "Epoch 10, Step 630, Train Loss: 0.0066, Valid Loss: 0.7066\n",
            "Epoch 11, Step 640, Train Loss: 0.0040, Valid Loss: 0.6934\n",
            "Epoch 11, Step 650, Train Loss: 0.0027, Valid Loss: 0.6953\n",
            "Epoch 11, Step 660, Train Loss: 0.0033, Valid Loss: 0.7012\n",
            "Epoch 11, Step 670, Train Loss: 0.0023, Valid Loss: 0.7075\n",
            "Epoch 11, Step 680, Train Loss: 0.0027, Valid Loss: 0.7190\n",
            "Epoch 11, Step 690, Train Loss: 0.0038, Valid Loss: 0.7283\n",
            "Epoch 12, Step 700, Train Loss: 0.0045, Valid Loss: 0.7308\n",
            "Epoch 12, Step 710, Train Loss: 0.0024, Valid Loss: 0.7362\n",
            "Epoch 12, Step 720, Train Loss: 0.0020, Valid Loss: 0.7405\n",
            "Epoch 12, Step 730, Train Loss: 0.0021, Valid Loss: 0.7492\n",
            "Epoch 12, Step 740, Train Loss: 0.0015, Valid Loss: 0.7593\n",
            "Epoch 12, Step 750, Train Loss: 0.0017, Valid Loss: 0.7665\n",
            "Epoch 13, Step 760, Train Loss: 0.0024, Valid Loss: 0.7498\n",
            "Epoch 13, Step 770, Train Loss: 0.0017, Valid Loss: 0.7468\n",
            "Epoch 13, Step 780, Train Loss: 0.0015, Valid Loss: 0.7524\n",
            "Epoch 13, Step 790, Train Loss: 0.0014, Valid Loss: 0.7581\n",
            "Epoch 13, Step 800, Train Loss: 0.0017, Valid Loss: 0.7662\n",
            "Epoch 13, Step 810, Train Loss: 0.0010, Valid Loss: 0.7733\n",
            "Epoch 14, Step 820, Train Loss: 0.0012, Valid Loss: 0.7801\n",
            "Epoch 14, Step 830, Train Loss: 0.0013, Valid Loss: 0.7877\n",
            "Epoch 14, Step 840, Train Loss: 0.0019, Valid Loss: 0.7938\n",
            "Epoch 14, Step 850, Train Loss: 0.0008, Valid Loss: 0.7947\n",
            "Epoch 14, Step 860, Train Loss: 0.0007, Valid Loss: 0.7978\n",
            "Epoch 14, Step 870, Train Loss: 0.0014, Valid Loss: 0.8012\n",
            "Epoch 14, Step 880, Train Loss: 0.0008, Valid Loss: 0.8028\n",
            "Epoch 15, Step 890, Train Loss: 0.0015, Valid Loss: 0.8068\n",
            "Epoch 15, Step 900, Train Loss: 0.0016, Valid Loss: 0.8120\n",
            "Epoch 15, Step 910, Train Loss: 0.0011, Valid Loss: 0.8140\n",
            "Epoch 15, Step 920, Train Loss: 0.0010, Valid Loss: 0.8159\n",
            "Epoch 15, Step 930, Train Loss: 0.0006, Valid Loss: 0.8193\n",
            "Epoch 15, Step 940, Train Loss: 0.0009, Valid Loss: 0.8220\n",
            "Epoch 16, Step 950, Train Loss: 0.0010, Valid Loss: 0.8242\n",
            "Epoch 16, Step 960, Train Loss: 0.0011, Valid Loss: 0.8261\n",
            "Epoch 16, Step 970, Train Loss: 0.0007, Valid Loss: 0.8293\n",
            "Epoch 16, Step 980, Train Loss: 0.0006, Valid Loss: 0.8324\n",
            "Epoch 16, Step 990, Train Loss: 0.0006, Valid Loss: 0.8363\n",
            "Epoch 16, Step 1000, Train Loss: 0.0007, Valid Loss: 0.8406\n",
            "Epoch 17, Step 1010, Train Loss: 0.0006, Valid Loss: 0.8441\n",
            "Epoch 17, Step 1020, Train Loss: 0.0009, Valid Loss: 0.8492\n",
            "Epoch 17, Step 1030, Train Loss: 0.0006, Valid Loss: 0.8548\n",
            "Epoch 17, Step 1040, Train Loss: 0.0006, Valid Loss: 0.8571\n",
            "Epoch 17, Step 1050, Train Loss: 0.0008, Valid Loss: 0.8589\n",
            "Epoch 17, Step 1060, Train Loss: 0.0006, Valid Loss: 0.8616\n",
            "Epoch 17, Step 1070, Train Loss: 0.0005, Valid Loss: 0.8632\n",
            "Epoch 18, Step 1080, Train Loss: 0.0009, Valid Loss: 0.8677\n",
            "Epoch 18, Step 1090, Train Loss: 0.0005, Valid Loss: 0.8724\n",
            "Epoch 18, Step 1100, Train Loss: 0.0006, Valid Loss: 0.8720\n",
            "Epoch 18, Step 1110, Train Loss: 0.0007, Valid Loss: 0.8706\n",
            "Epoch 18, Step 1120, Train Loss: 0.0003, Valid Loss: 0.8728\n",
            "Epoch 18, Step 1130, Train Loss: 0.0004, Valid Loss: 0.8757\n",
            "Epoch 19, Step 1140, Train Loss: 0.0006, Valid Loss: 0.8834\n",
            "Epoch 19, Step 1150, Train Loss: 0.0010, Valid Loss: 0.8921\n",
            "Epoch 19, Step 1160, Train Loss: 0.0003, Valid Loss: 0.8958\n",
            "Epoch 19, Step 1170, Train Loss: 0.0003, Valid Loss: 0.8975\n",
            "Epoch 19, Step 1180, Train Loss: 0.0004, Valid Loss: 0.8993\n",
            "Epoch 19, Step 1190, Train Loss: 0.0005, Valid Loss: 0.8969\n",
            "Epoch 20, Step 1200, Train Loss: 0.0004, Valid Loss: 0.8910\n",
            "Epoch 20, Step 1210, Train Loss: 0.0008, Valid Loss: 0.8931\n",
            "Epoch 20, Step 1220, Train Loss: 0.0005, Valid Loss: 0.8989\n",
            "Epoch 20, Step 1230, Train Loss: 0.0008, Valid Loss: 0.9060\n",
            "Epoch 20, Step 1240, Train Loss: 0.0004, Valid Loss: 0.9108\n",
            "Epoch 20, Step 1250, Train Loss: 0.0003, Valid Loss: 0.9149\n",
            "Epoch 20, Step 1260, Train Loss: 0.0004, Valid Loss: 0.9156\n",
            "Epoch 21, Step 1270, Train Loss: 0.0006, Valid Loss: 0.9134\n",
            "Epoch 21, Step 1280, Train Loss: 0.0003, Valid Loss: 0.9141\n",
            "Epoch 21, Step 1290, Train Loss: 0.0004, Valid Loss: 0.9133\n",
            "Epoch 21, Step 1300, Train Loss: 0.0005, Valid Loss: 0.9096\n",
            "Epoch 21, Step 1310, Train Loss: 0.0003, Valid Loss: 0.9103\n",
            "Epoch 21, Step 1320, Train Loss: 0.0002, Valid Loss: 0.9137\n",
            "Epoch 22, Step 1330, Train Loss: 0.0005, Valid Loss: 0.9207\n",
            "Epoch 22, Step 1340, Train Loss: 0.0004, Valid Loss: 0.9281\n",
            "Epoch 22, Step 1350, Train Loss: 0.0003, Valid Loss: 0.9327\n",
            "Epoch 22, Step 1360, Train Loss: 0.0004, Valid Loss: 0.9355\n",
            "Epoch 22, Step 1370, Train Loss: 0.0002, Valid Loss: 0.9358\n",
            "Epoch 22, Step 1380, Train Loss: 0.0003, Valid Loss: 0.9387\n",
            "Epoch 23, Step 1390, Train Loss: 0.0004, Valid Loss: 0.9399\n",
            "Epoch 23, Step 1400, Train Loss: 0.0004, Valid Loss: 0.9415\n",
            "Epoch 23, Step 1410, Train Loss: 0.0004, Valid Loss: 0.9430\n",
            "Epoch 23, Step 1420, Train Loss: 0.0004, Valid Loss: 0.9492\n",
            "Epoch 23, Step 1430, Train Loss: 0.0002, Valid Loss: 0.9526\n",
            "Epoch 23, Step 1440, Train Loss: 0.0002, Valid Loss: 0.9542\n",
            "Epoch 24, Step 1450, Train Loss: 0.0003, Valid Loss: 0.9565\n",
            "Epoch 24, Step 1460, Train Loss: 0.0005, Valid Loss: 0.9600\n",
            "Epoch 24, Step 1470, Train Loss: 0.0004, Valid Loss: 0.9644\n",
            "Epoch 24, Step 1480, Train Loss: 0.0002, Valid Loss: 0.9643\n",
            "Epoch 24, Step 1490, Train Loss: 0.0002, Valid Loss: 0.9633\n",
            "Epoch 24, Step 1500, Train Loss: 0.0002, Valid Loss: 0.9635\n",
            "Epoch 24, Step 1510, Train Loss: 0.0002, Valid Loss: 0.9649\n",
            "Epoch 25, Step 1520, Train Loss: 0.0003, Valid Loss: 0.9686\n",
            "Epoch 25, Step 1530, Train Loss: 0.0004, Valid Loss: 0.9722\n",
            "Epoch 25, Step 1540, Train Loss: 0.0003, Valid Loss: 0.9739\n",
            "Epoch 25, Step 1550, Train Loss: 0.0002, Valid Loss: 0.9753\n",
            "Epoch 25, Step 1560, Train Loss: 0.0001, Valid Loss: 0.9771\n",
            "Epoch 25, Step 1570, Train Loss: 0.0002, Valid Loss: 0.9781\n",
            "Epoch 26, Step 1580, Train Loss: 0.0003, Valid Loss: 0.9820\n",
            "Epoch 26, Step 1590, Train Loss: 0.0002, Valid Loss: 0.9855\n",
            "Epoch 26, Step 1600, Train Loss: 0.0002, Valid Loss: 0.9856\n",
            "Epoch 26, Step 1610, Train Loss: 0.0002, Valid Loss: 0.9853\n",
            "Epoch 26, Step 1620, Train Loss: 0.0002, Valid Loss: 0.9869\n",
            "Epoch 26, Step 1630, Train Loss: 0.0002, Valid Loss: 0.9881\n",
            "Epoch 27, Step 1640, Train Loss: 0.0003, Valid Loss: 0.9906\n",
            "Epoch 27, Step 1650, Train Loss: 0.0003, Valid Loss: 0.9933\n",
            "Epoch 27, Step 1660, Train Loss: 0.0002, Valid Loss: 0.9959\n",
            "Epoch 27, Step 1670, Train Loss: 0.0001, Valid Loss: 0.9969\n",
            "Epoch 27, Step 1680, Train Loss: 0.0001, Valid Loss: 0.9985\n",
            "Epoch 27, Step 1690, Train Loss: 0.0002, Valid Loss: 1.0008\n",
            "Epoch 27, Step 1700, Train Loss: 0.0002, Valid Loss: 0.9991\n",
            "Epoch 28, Step 1710, Train Loss: 0.0003, Valid Loss: 1.0012\n",
            "Epoch 28, Step 1720, Train Loss: 0.0002, Valid Loss: 1.0056\n",
            "Epoch 28, Step 1730, Train Loss: 0.0002, Valid Loss: 1.0079\n",
            "Epoch 28, Step 1740, Train Loss: 0.0001, Valid Loss: 1.0093\n",
            "Epoch 28, Step 1750, Train Loss: 0.0001, Valid Loss: 1.0118\n",
            "Epoch 28, Step 1760, Train Loss: 0.0001, Valid Loss: 1.0120\n",
            "Epoch 29, Step 1770, Train Loss: 0.0002, Valid Loss: 1.0143\n",
            "Epoch 29, Step 1780, Train Loss: 0.0003, Valid Loss: 1.0196\n",
            "Epoch 29, Step 1790, Train Loss: 0.0002, Valid Loss: 1.0213\n",
            "Epoch 29, Step 1800, Train Loss: 0.0001, Valid Loss: 1.0219\n",
            "Epoch 29, Step 1810, Train Loss: 0.0001, Valid Loss: 1.0230\n",
            "Epoch 29, Step 1820, Train Loss: 0.0002, Valid Loss: 1.0248\n",
            "Epoch 30, Step 1830, Train Loss: 0.0002, Valid Loss: 1.0248\n",
            "Epoch 30, Step 1840, Train Loss: 0.0002, Valid Loss: 1.0276\n",
            "Epoch 30, Step 1850, Train Loss: 0.0001, Valid Loss: 1.0303\n",
            "Epoch 30, Step 1860, Train Loss: 0.0001, Valid Loss: 1.0315\n",
            "Epoch 30, Step 1870, Train Loss: 0.0001, Valid Loss: 1.0304\n",
            "Epoch 30, Step 1880, Train Loss: 0.0002, Valid Loss: 1.0345\n",
            "Epoch 30, Step 1890, Train Loss: 0.0001, Valid Loss: 1.0363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-wJEf05DJ8Q"
      },
      "source": [
        "## 결과 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFiSShyMDLOX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "02c080fd-026e-431f-afc9-c03913917876"
      },
      "source": [
        "draw_graph(output_file_path, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBQbmatqwSe_"
      },
      "source": [
        "## 추가 질문\n",
        "\n",
        "위의 그림을 보면서 최적의 Epoch 개수를 찾아보세요."
      ]
    }
  ]
}